{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "torch version : 1.12.1\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "print(device)\n",
    "print(f'torch version : {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(41) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./train/0000.jpg</td>\n",
       "      <td>Diego Velazquez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./train/0001.jpg</td>\n",
       "      <td>Vincent van Gogh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./train/0002.jpg</td>\n",
       "      <td>Claude Monet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./train/0003.jpg</td>\n",
       "      <td>Edgar Degas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>./train/0004.jpg</td>\n",
       "      <td>Hieronymus Bosch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          img_path            artist\n",
       "0   0  ./train/0000.jpg   Diego Velazquez\n",
       "1   1  ./train/0001.jpg  Vincent van Gogh\n",
       "2   2  ./train/0002.jpg      Claude Monet\n",
       "3   3  ./train/0003.jpg       Edgar Degas\n",
       "4   4  ./train/0004.jpg  Hieronymus Bosch"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Dataset/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "classes = {}\n",
    "for i in df['artist']:\n",
    "    if i not in classes:\n",
    "        # count 데이터 수\n",
    "        classes[i] = 0\n",
    "    else:\n",
    "        classes[i] +=1\n",
    "# i번째 라벨 = [화가이름, image 수]\n",
    "convert_labels = sorted(classes.items(), key=lambda x : x[1], reverse=True)\n",
    "\n",
    "# key= 화가이름 value = [라벨번호, count 수]\n",
    "for i in range(len(convert_labels)):\n",
    "    classes[convert_labels[i][0]]=[i,convert_labels[i][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>years</th>\n",
       "      <th>genre</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amedeo Modigliani</td>\n",
       "      <td>1884 - 1920</td>\n",
       "      <td>Expressionism</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vasiliy Kandinskiy</td>\n",
       "      <td>1866 - 1944</td>\n",
       "      <td>Expressionism,Abstractionism</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diego Rivera</td>\n",
       "      <td>1886 - 1957</td>\n",
       "      <td>Social Realism,Muralism</td>\n",
       "      <td>Mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Claude Monet</td>\n",
       "      <td>1840 - 1926</td>\n",
       "      <td>Impressionism</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rene Magritte</td>\n",
       "      <td>1898 - 1967</td>\n",
       "      <td>Surrealism,Impressionism</td>\n",
       "      <td>Belgian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name        years                         genre nationality\n",
       "0   Amedeo Modigliani  1884 - 1920                 Expressionism     Italian\n",
       "1  Vasiliy Kandinskiy  1866 - 1944  Expressionism,Abstractionism     Russian\n",
       "2        Diego Rivera  1886 - 1957       Social Realism,Muralism     Mexican\n",
       "3        Claude Monet  1840 - 1926                 Impressionism      French\n",
       "4       Rene Magritte  1898 - 1967      Surrealism,Impressionism     Belgian"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv('./Dataset/artists_info.csv')\n",
    "print(len(new_df))\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vincent van Gogh\n",
      "[0, 628, '1853 ??1890', 'Post-Impressionism', 'Dutch']\n",
      "Edgar Degas\n",
      "[1, 488, '1834 - 1917', 'Impressionism', 'French']\n",
      "Pablo Picasso\n",
      "[2, 302, '1881 - 1973', 'Cubism', 'Spanish']\n",
      "Pierre-Auguste Renoir\n",
      "[3, 232, '1841 - 1919', 'Impressionism', 'French']\n",
      "Albrecht Du rer\n",
      "[4, 219]\n",
      "Paul Gauguin\n",
      "[5, 219, '1848 ??1903', 'Symbolism,Post-Impressionism', 'French']\n",
      "Francisco Goya\n",
      "[6, 203, '1746 - 1828', 'Romanticism', 'Spanish']\n",
      "Rembrandt\n",
      "[7, 180, '1606 - 1669', 'Baroque', 'Dutch']\n",
      "Titian\n",
      "[8, 172, '1488 - 1576', 'High Renaissance,Mannerism', 'Italian']\n",
      "Marc Chagall\n",
      "[9, 172, '1887 - 1985', 'Primitivism', 'French,Jewish,Belarusian']\n",
      "Alfred Sisley\n",
      "[10, 164, '1839 - 1899', 'Impressionism', 'French,British']\n",
      "Paul Klee\n",
      "[11, 141, '1879 ??1940', 'Expressionism,Abstractionism,Surrealism', 'German,Swiss']\n",
      "Rene Magritte\n",
      "[12, 136, '1898 - 1967', 'Surrealism,Impressionism', 'Belgian']\n",
      "Andy Warhol\n",
      "[13, 131, '1928 ??1987', 'Pop Art', 'American']\n",
      "Amedeo Modigliani\n",
      "[14, 131, '1884 - 1920', 'Expressionism', 'Italian']\n",
      "Henri Matisse\n",
      "[15, 120, '1869 - 1954', 'Impressionism,Post-Impressionism', 'French']\n",
      "Sandro Botticelli\n",
      "[16, 119, '1445 - 1510', 'Early Renaissance', 'Italian']\n",
      "Mikhail Vrubel\n",
      "[17, 117, '1856 - 1910', 'Symbolism', 'Russian']\n",
      "Hieronymus Bosch\n",
      "[18, 114, '1450 - 1516', 'Northern Renaissance', 'Dutch']\n",
      "Leonardo da Vinci\n",
      "[19, 100, '1452 - 1519', 'High Renaissance', 'Italian']\n",
      "Salvador Dali\n",
      "[20, 98, '1904 - 1989', 'Surrealism', 'Spanish']\n",
      "Peter Paul Rubens\n",
      "[21, 96, '1577 - 1640', 'Baroque', 'Flemish']\n",
      "Kazimir Malevich\n",
      "[22, 90, '1879 - 1935', 'Suprematism', 'Russian']\n",
      "Pieter Bruegel\n",
      "[23, 84, '1525 - 1569', 'Northern Renaissance', 'Flemish']\n",
      "Frida Kahlo\n",
      "[24, 83, '1907 - 1954', 'Primitivism,Surrealism', 'Mexican']\n",
      "Diego Velazquez\n",
      "[25, 80, '1599 - 1660', 'Baroque', 'Spanish']\n",
      "Joan Miro\n",
      "[26, 75, '1893 ??1983', 'Surrealism', 'Spanish']\n",
      "Andrei Rublev\n",
      "[27, 73, '1360 - 1430', 'Byzantine Art', 'Russian']\n",
      "Raphael\n",
      "[28, 72, '1483 ??1520', 'High Renaissance', 'Italian']\n",
      "Giotto di Bondone\n",
      "[29, 71, '1266 - 1337', 'Proto Renaissance', 'Italian']\n",
      "Gustav Klimt\n",
      "[30, 68, '1862 - 1918', 'Symbolism,Art Nouveau', 'Austrian']\n",
      "El Greco\n",
      "[31, 64, '1541 - 1614', 'Mannerism', 'Spanish,Greek']\n",
      "Jan van Eyck\n",
      "[32, 63, '1395 - 1441', 'Northern Renaissance', 'Flemish']\n",
      "Camille Pissarro\n",
      "[33, 63, '1830 - 1903', 'Impressionism,Post-Impressionism', 'French']\n",
      "Edouard Manet\n",
      "[34, 61, '1832 - 1883', 'Realism,Impressionism', 'French']\n",
      "Henri de Toulouse-Lautrec\n",
      "[35, 60, '1864 ??1901', 'Post-Impressionism', 'French']\n",
      "Vasiliy Kandinskiy\n",
      "[36, 59, '1866 - 1944', 'Expressionism,Abstractionism', 'Russian']\n",
      "Claude Monet\n",
      "[37, 58, '1840 - 1926', 'Impressionism', 'French']\n",
      "Piet Mondrian\n",
      "[38, 58, '1872 ??1944', 'Neoplasticism', 'Dutch']\n",
      "Henri Rousseau\n",
      "[39, 51, '1844 ??1910', 'Primitivism', 'French']\n",
      "Diego Rivera\n",
      "[40, 49, '1886 - 1957', 'Social Realism,Muralism', 'Mexican']\n",
      "William Turner\n",
      "[41, 43, '1775 - 1851', 'Romanticism', 'British']\n",
      "Edvard Munch\n",
      "[42, 43, '1863 - 1944', 'Symbolism,Expressionism', 'Norwegian']\n",
      "Gustave Courbet\n",
      "[43, 41, '1819 - 1877', 'Realism', 'French']\n",
      "Michelangelo\n",
      "[44, 33, '1475 ??1564', 'High Renaissance', 'Italian']\n",
      "Paul Cezanne\n",
      "[45, 32, '1839 ??1906', 'Post-Impressionism', 'French']\n",
      "Caravaggio\n",
      "[46, 31, '1571 - 1610', 'Baroque', 'Italian']\n",
      "Georges Seurat\n",
      "[47, 29, '1859 ??1891', 'Post-Impressionism', 'French']\n",
      "Eugene Delacroix\n",
      "[48, 25, '1798 ??1863', 'Romanticism', 'French']\n",
      "Jackson Pollock\n",
      "[49, 20, '1912 ??1956', 'Abstract Expressionism', 'American']\n"
     ]
    }
   ],
   "source": [
    "# classes [label, count, years, genre, nationality]\n",
    "for name in classes.keys():\n",
    "    for i in range(len(new_df)):\n",
    "        if new_df.loc[i]['name'] == name:\n",
    "            classes[name].extend(new_df.loc[i].iloc[1:])\n",
    "            classes[name] = classes[name]\n",
    "classes = OrderedDict(sorted(classes.items(), key = lambda t : t[1][1],reverse=True))\n",
    "for i in range(50):\n",
    "    print(list(classes.keys())[i])\n",
    "    print(classes[list(classes.keys())[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(df,number,class_info,seed):\n",
    "    print(f'total data : {len(df)}')\n",
    "    for i in class_info:\n",
    "        if class_info[i][1] > number:\n",
    "            a = df[df['artist']==i]\n",
    "            drop_index = list(a.sample(class_info[i][1]-number,random_state=seed)['id'])\n",
    "            class_info[i][1]=number\n",
    "            print(f'{i} delete {len(drop_index)}')\n",
    "            df.drop(index=drop_index,inplace=True,axis=0)\n",
    "    print(f'ater data : {len(df)}')\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data : 5911\n",
      "Vincent van Gogh delete 428\n",
      "Edgar Degas delete 288\n",
      "Pablo Picasso delete 102\n",
      "Pierre-Auguste Renoir delete 32\n",
      "Albrecht Du rer delete 19\n",
      "Paul Gauguin delete 19\n",
      "Francisco Goya delete 3\n",
      "ater data : 5020\n",
      "OrderedDict([('Vincent van Gogh', [0, 200, '1853 ??1890', 'Post-Impressionism', 'Dutch']), ('Edgar Degas', [1, 200, '1834 - 1917', 'Impressionism', 'French']), ('Pablo Picasso', [2, 200, '1881 - 1973', 'Cubism', 'Spanish']), ('Pierre-Auguste Renoir', [3, 200, '1841 - 1919', 'Impressionism', 'French']), ('Albrecht Du rer', [4, 200]), ('Paul Gauguin', [5, 200, '1848 ??1903', 'Symbolism,Post-Impressionism', 'French']), ('Francisco Goya', [6, 200, '1746 - 1828', 'Romanticism', 'Spanish']), ('Rembrandt', [7, 180, '1606 - 1669', 'Baroque', 'Dutch']), ('Titian', [8, 172, '1488 - 1576', 'High Renaissance,Mannerism', 'Italian']), ('Marc Chagall', [9, 172, '1887 - 1985', 'Primitivism', 'French,Jewish,Belarusian']), ('Alfred Sisley', [10, 164, '1839 - 1899', 'Impressionism', 'French,British']), ('Paul Klee', [11, 141, '1879 ??1940', 'Expressionism,Abstractionism,Surrealism', 'German,Swiss']), ('Rene Magritte', [12, 136, '1898 - 1967', 'Surrealism,Impressionism', 'Belgian']), ('Andy Warhol', [13, 131, '1928 ??1987', 'Pop Art', 'American']), ('Amedeo Modigliani', [14, 131, '1884 - 1920', 'Expressionism', 'Italian']), ('Henri Matisse', [15, 120, '1869 - 1954', 'Impressionism,Post-Impressionism', 'French']), ('Sandro Botticelli', [16, 119, '1445 - 1510', 'Early Renaissance', 'Italian']), ('Mikhail Vrubel', [17, 117, '1856 - 1910', 'Symbolism', 'Russian']), ('Hieronymus Bosch', [18, 114, '1450 - 1516', 'Northern Renaissance', 'Dutch']), ('Leonardo da Vinci', [19, 100, '1452 - 1519', 'High Renaissance', 'Italian']), ('Salvador Dali', [20, 98, '1904 - 1989', 'Surrealism', 'Spanish']), ('Peter Paul Rubens', [21, 96, '1577 - 1640', 'Baroque', 'Flemish']), ('Kazimir Malevich', [22, 90, '1879 - 1935', 'Suprematism', 'Russian']), ('Pieter Bruegel', [23, 84, '1525 - 1569', 'Northern Renaissance', 'Flemish']), ('Frida Kahlo', [24, 83, '1907 - 1954', 'Primitivism,Surrealism', 'Mexican']), ('Diego Velazquez', [25, 80, '1599 - 1660', 'Baroque', 'Spanish']), ('Joan Miro', [26, 75, '1893 ??1983', 'Surrealism', 'Spanish']), ('Andrei Rublev', [27, 73, '1360 - 1430', 'Byzantine Art', 'Russian']), ('Raphael', [28, 72, '1483 ??1520', 'High Renaissance', 'Italian']), ('Giotto di Bondone', [29, 71, '1266 - 1337', 'Proto Renaissance', 'Italian']), ('Gustav Klimt', [30, 68, '1862 - 1918', 'Symbolism,Art Nouveau', 'Austrian']), ('El Greco', [31, 64, '1541 - 1614', 'Mannerism', 'Spanish,Greek']), ('Jan van Eyck', [32, 63, '1395 - 1441', 'Northern Renaissance', 'Flemish']), ('Camille Pissarro', [33, 63, '1830 - 1903', 'Impressionism,Post-Impressionism', 'French']), ('Edouard Manet', [34, 61, '1832 - 1883', 'Realism,Impressionism', 'French']), ('Henri de Toulouse-Lautrec', [35, 60, '1864 ??1901', 'Post-Impressionism', 'French']), ('Vasiliy Kandinskiy', [36, 59, '1866 - 1944', 'Expressionism,Abstractionism', 'Russian']), ('Claude Monet', [37, 58, '1840 - 1926', 'Impressionism', 'French']), ('Piet Mondrian', [38, 58, '1872 ??1944', 'Neoplasticism', 'Dutch']), ('Henri Rousseau', [39, 51, '1844 ??1910', 'Primitivism', 'French']), ('Diego Rivera', [40, 49, '1886 - 1957', 'Social Realism,Muralism', 'Mexican']), ('William Turner', [41, 43, '1775 - 1851', 'Romanticism', 'British']), ('Edvard Munch', [42, 43, '1863 - 1944', 'Symbolism,Expressionism', 'Norwegian']), ('Gustave Courbet', [43, 41, '1819 - 1877', 'Realism', 'French']), ('Michelangelo', [44, 33, '1475 ??1564', 'High Renaissance', 'Italian']), ('Paul Cezanne', [45, 32, '1839 ??1906', 'Post-Impressionism', 'French']), ('Caravaggio', [46, 31, '1571 - 1610', 'Baroque', 'Italian']), ('Georges Seurat', [47, 29, '1859 ??1891', 'Post-Impressionism', 'French']), ('Eugene Delacroix', [48, 25, '1798 ??1863', 'Romanticism', 'French']), ('Jackson Pollock', [49, 20, '1912 ??1956', 'Abstract Expressionism', 'American'])])\n"
     ]
    }
   ],
   "source": [
    "df = cut_data(df,200,classes,41)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, classes , infer=False):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    if infer:\n",
    "        return df['img_path'].values\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        labels.append(classes[df['artist'].iloc[i]][0])\n",
    "        imgs.append([df['img_path'].iloc[i]])\n",
    "\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({25: 201, 37: 201, 18: 201, 3: 201, 12: 201, 44: 201, 21: 201, 46: 201, 10: 201, 34: 201, 7: 201, 6: 201, 1: 201, 2: 201, 8: 201, 17: 201, 19: 201, 22: 201, 13: 201, 36: 201, 30: 201, 14: 201, 39: 201, 20: 201, 23: 201, 0: 201, 4: 201, 5: 201, 16: 201, 38: 201, 48: 201, 11: 201, 41: 201, 9: 201, 32: 201, 15: 201, 31: 201, 43: 201, 27: 201, 49: 201, 42: 201, 33: 201, 28: 201, 35: 201, 26: 201, 29: 201, 40: 201, 24: 201, 47: 201, 45: 201})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "all_imgs , all_labels = get_data(df,classes= classes)\n",
    "\n",
    "oversampling = RandomOverSampler(random_state=42)\n",
    "all_imgs, all_labels = oversampling.fit_resample(all_imgs, all_labels)\n",
    "print(Counter(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, class_info,transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        self.classes = class_info\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = './Dataset'+self.img_paths[index][1:]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = torch.zeros([50], dtype=torch.float32)\n",
    "            # label[self.classes[self.labels[index]][0]] = 1\n",
    "            label[self.labels[index]] = 1\n",
    "            # print(f'artist name {self.labels[index]} , label = {self.classes[self.labels[index]][0]}')\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)      \n",
    "    \n",
    "    def getclasses(self):\n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomCrop(224,224),\n",
    "    A.HorizontalFlip( p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, p=0.5),\n",
    "    # A.CoarseDropout(max_holes=4, max_height=16, max_width=16, \n",
    "    #                          min_holes=None, min_height=16, min_width=16,always_apply=False, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std= (0.229,0.224,0.224), max_pixel_value=255),\n",
    "    #A.Normalize(max_pixel_value=255),\n",
    "    # (HxWxC) -> (CxHxW)\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    #A.Normalize(max_pixel_value=255),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std= (0.229,0.224,0.224), max_pixel_value=255),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import convnext_large,ConvNeXt_Large_Weights\n",
    "from torchvision import models\n",
    "\n",
    "import timm\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=len(classes)):\n",
    "        super(BaseModel, self).__init__()\n",
    "        #self.backbone = convnext_large(weight=ConvNeXt_Large_Weights.DEFAULT)\n",
    "        # self.backbone = models.convnext_base(weights=models.ConvNeXt_Base_Weights.DEFAULT)\n",
    "        # self.backbone = models.convnext_small(weights=models.ConvNeXt_Small_Weights.IMAGENET1K_V1)\n",
    "        #self.backbone= models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "        #self.backbone = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "        self.backbone = models.swin_s(weights=models.Swin_S_Weights.IMAGENET1K_V1)\n",
    "        self.classifier = nn.Linear(1000, num_classes)\n",
    "        self.drop = nn.Dropout(0.5,inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
      "           Permute-2           [-1, 56, 56, 96]               0\n",
      "         LayerNorm-3           [-1, 56, 56, 96]             192\n",
      "         LayerNorm-4           [-1, 56, 56, 96]             192\n",
      "ShiftedWindowAttention-5           [-1, 56, 56, 96]               0\n",
      "   StochasticDepth-6           [-1, 56, 56, 96]               0\n",
      "         LayerNorm-7           [-1, 56, 56, 96]             192\n",
      "            Linear-8          [-1, 56, 56, 384]          37,248\n",
      "              GELU-9          [-1, 56, 56, 384]               0\n",
      "          Dropout-10          [-1, 56, 56, 384]               0\n",
      "           Linear-11           [-1, 56, 56, 96]          36,960\n",
      "          Dropout-12           [-1, 56, 56, 96]               0\n",
      "  StochasticDepth-13           [-1, 56, 56, 96]               0\n",
      "SwinTransformerBlock-14           [-1, 56, 56, 96]               0\n",
      "        LayerNorm-15           [-1, 56, 56, 96]             192\n",
      "ShiftedWindowAttention-16           [-1, 56, 56, 96]               0\n",
      "  StochasticDepth-17           [-1, 56, 56, 96]               0\n",
      "        LayerNorm-18           [-1, 56, 56, 96]             192\n",
      "           Linear-19          [-1, 56, 56, 384]          37,248\n",
      "             GELU-20          [-1, 56, 56, 384]               0\n",
      "          Dropout-21          [-1, 56, 56, 384]               0\n",
      "           Linear-22           [-1, 56, 56, 96]          36,960\n",
      "          Dropout-23           [-1, 56, 56, 96]               0\n",
      "  StochasticDepth-24           [-1, 56, 56, 96]               0\n",
      "SwinTransformerBlock-25           [-1, 56, 56, 96]               0\n",
      "        LayerNorm-26          [-1, 28, 28, 384]             768\n",
      "           Linear-27          [-1, 28, 28, 192]          73,728\n",
      "     PatchMerging-28          [-1, 28, 28, 192]               0\n",
      "        LayerNorm-29          [-1, 28, 28, 192]             384\n",
      "ShiftedWindowAttention-30          [-1, 28, 28, 192]               0\n",
      "  StochasticDepth-31          [-1, 28, 28, 192]               0\n",
      "        LayerNorm-32          [-1, 28, 28, 192]             384\n",
      "           Linear-33          [-1, 28, 28, 768]         148,224\n",
      "             GELU-34          [-1, 28, 28, 768]               0\n",
      "          Dropout-35          [-1, 28, 28, 768]               0\n",
      "           Linear-36          [-1, 28, 28, 192]         147,648\n",
      "          Dropout-37          [-1, 28, 28, 192]               0\n",
      "  StochasticDepth-38          [-1, 28, 28, 192]               0\n",
      "SwinTransformerBlock-39          [-1, 28, 28, 192]               0\n",
      "        LayerNorm-40          [-1, 28, 28, 192]             384\n",
      "ShiftedWindowAttention-41          [-1, 28, 28, 192]               0\n",
      "  StochasticDepth-42          [-1, 28, 28, 192]               0\n",
      "        LayerNorm-43          [-1, 28, 28, 192]             384\n",
      "           Linear-44          [-1, 28, 28, 768]         148,224\n",
      "             GELU-45          [-1, 28, 28, 768]               0\n",
      "          Dropout-46          [-1, 28, 28, 768]               0\n",
      "           Linear-47          [-1, 28, 28, 192]         147,648\n",
      "          Dropout-48          [-1, 28, 28, 192]               0\n",
      "  StochasticDepth-49          [-1, 28, 28, 192]               0\n",
      "SwinTransformerBlock-50          [-1, 28, 28, 192]               0\n",
      "        LayerNorm-51          [-1, 14, 14, 768]           1,536\n",
      "           Linear-52          [-1, 14, 14, 384]         294,912\n",
      "     PatchMerging-53          [-1, 14, 14, 384]               0\n",
      "        LayerNorm-54          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-55          [-1, 14, 14, 384]               0\n",
      "  StochasticDepth-56          [-1, 14, 14, 384]               0\n",
      "        LayerNorm-57          [-1, 14, 14, 384]             768\n",
      "           Linear-58         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-59         [-1, 14, 14, 1536]               0\n",
      "          Dropout-60         [-1, 14, 14, 1536]               0\n",
      "           Linear-61          [-1, 14, 14, 384]         590,208\n",
      "          Dropout-62          [-1, 14, 14, 384]               0\n",
      "  StochasticDepth-63          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-64          [-1, 14, 14, 384]               0\n",
      "        LayerNorm-65          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-66          [-1, 14, 14, 384]               0\n",
      "  StochasticDepth-67          [-1, 14, 14, 384]               0\n",
      "        LayerNorm-68          [-1, 14, 14, 384]             768\n",
      "           Linear-69         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-70         [-1, 14, 14, 1536]               0\n",
      "          Dropout-71         [-1, 14, 14, 1536]               0\n",
      "           Linear-72          [-1, 14, 14, 384]         590,208\n",
      "          Dropout-73          [-1, 14, 14, 384]               0\n",
      "  StochasticDepth-74          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-75          [-1, 14, 14, 384]               0\n",
      "        LayerNorm-76          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-77          [-1, 14, 14, 384]               0\n",
      "  StochasticDepth-78          [-1, 14, 14, 384]               0\n",
      "        LayerNorm-79          [-1, 14, 14, 384]             768\n",
      "           Linear-80         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-81         [-1, 14, 14, 1536]               0\n",
      "          Dropout-82         [-1, 14, 14, 1536]               0\n",
      "           Linear-83          [-1, 14, 14, 384]         590,208\n",
      "          Dropout-84          [-1, 14, 14, 384]               0\n",
      "  StochasticDepth-85          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-86          [-1, 14, 14, 384]               0\n",
      "        LayerNorm-87          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-88          [-1, 14, 14, 384]               0\n",
      "  StochasticDepth-89          [-1, 14, 14, 384]               0\n",
      "        LayerNorm-90          [-1, 14, 14, 384]             768\n",
      "           Linear-91         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-92         [-1, 14, 14, 1536]               0\n",
      "          Dropout-93         [-1, 14, 14, 1536]               0\n",
      "           Linear-94          [-1, 14, 14, 384]         590,208\n",
      "          Dropout-95          [-1, 14, 14, 384]               0\n",
      "  StochasticDepth-96          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-97          [-1, 14, 14, 384]               0\n",
      "        LayerNorm-98          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-99          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-100          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-101          [-1, 14, 14, 384]             768\n",
      "          Linear-102         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-103         [-1, 14, 14, 1536]               0\n",
      "         Dropout-104         [-1, 14, 14, 1536]               0\n",
      "          Linear-105          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-106          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-107          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-108          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-109          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-110          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-111          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-112          [-1, 14, 14, 384]             768\n",
      "          Linear-113         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-114         [-1, 14, 14, 1536]               0\n",
      "         Dropout-115         [-1, 14, 14, 1536]               0\n",
      "          Linear-116          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-117          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-118          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-119          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-120          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-121          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-122          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-123          [-1, 14, 14, 384]             768\n",
      "          Linear-124         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-125         [-1, 14, 14, 1536]               0\n",
      "         Dropout-126         [-1, 14, 14, 1536]               0\n",
      "          Linear-127          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-128          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-129          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-130          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-131          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-132          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-133          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-134          [-1, 14, 14, 384]             768\n",
      "          Linear-135         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-136         [-1, 14, 14, 1536]               0\n",
      "         Dropout-137         [-1, 14, 14, 1536]               0\n",
      "          Linear-138          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-139          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-140          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-141          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-142          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-143          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-144          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-145          [-1, 14, 14, 384]             768\n",
      "          Linear-146         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-147         [-1, 14, 14, 1536]               0\n",
      "         Dropout-148         [-1, 14, 14, 1536]               0\n",
      "          Linear-149          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-150          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-151          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-152          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-153          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-154          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-155          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-156          [-1, 14, 14, 384]             768\n",
      "          Linear-157         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-158         [-1, 14, 14, 1536]               0\n",
      "         Dropout-159         [-1, 14, 14, 1536]               0\n",
      "          Linear-160          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-161          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-162          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-163          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-164          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-165          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-166          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-167          [-1, 14, 14, 384]             768\n",
      "          Linear-168         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-169         [-1, 14, 14, 1536]               0\n",
      "         Dropout-170         [-1, 14, 14, 1536]               0\n",
      "          Linear-171          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-172          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-173          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-174          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-175          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-176          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-177          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-178          [-1, 14, 14, 384]             768\n",
      "          Linear-179         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-180         [-1, 14, 14, 1536]               0\n",
      "         Dropout-181         [-1, 14, 14, 1536]               0\n",
      "          Linear-182          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-183          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-184          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-185          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-186          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-187          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-188          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-189          [-1, 14, 14, 384]             768\n",
      "          Linear-190         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-191         [-1, 14, 14, 1536]               0\n",
      "         Dropout-192         [-1, 14, 14, 1536]               0\n",
      "          Linear-193          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-194          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-195          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-196          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-197          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-198          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-199          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-200          [-1, 14, 14, 384]             768\n",
      "          Linear-201         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-202         [-1, 14, 14, 1536]               0\n",
      "         Dropout-203         [-1, 14, 14, 1536]               0\n",
      "          Linear-204          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-205          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-206          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-207          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-208          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-209          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-210          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-211          [-1, 14, 14, 384]             768\n",
      "          Linear-212         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-213         [-1, 14, 14, 1536]               0\n",
      "         Dropout-214         [-1, 14, 14, 1536]               0\n",
      "          Linear-215          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-216          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-217          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-218          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-219          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-220          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-221          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-222          [-1, 14, 14, 384]             768\n",
      "          Linear-223         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-224         [-1, 14, 14, 1536]               0\n",
      "         Dropout-225         [-1, 14, 14, 1536]               0\n",
      "          Linear-226          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-227          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-228          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-229          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-230          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-231          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-232          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-233          [-1, 14, 14, 384]             768\n",
      "          Linear-234         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-235         [-1, 14, 14, 1536]               0\n",
      "         Dropout-236         [-1, 14, 14, 1536]               0\n",
      "          Linear-237          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-238          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-239          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-240          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-241          [-1, 14, 14, 384]             768\n",
      "ShiftedWindowAttention-242          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-243          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-244          [-1, 14, 14, 384]             768\n",
      "          Linear-245         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-246         [-1, 14, 14, 1536]               0\n",
      "         Dropout-247         [-1, 14, 14, 1536]               0\n",
      "          Linear-248          [-1, 14, 14, 384]         590,208\n",
      "         Dropout-249          [-1, 14, 14, 384]               0\n",
      " StochasticDepth-250          [-1, 14, 14, 384]               0\n",
      "SwinTransformerBlock-251          [-1, 14, 14, 384]               0\n",
      "       LayerNorm-252           [-1, 7, 7, 1536]           3,072\n",
      "          Linear-253            [-1, 7, 7, 768]       1,179,648\n",
      "    PatchMerging-254            [-1, 7, 7, 768]               0\n",
      "       LayerNorm-255            [-1, 7, 7, 768]           1,536\n",
      "ShiftedWindowAttention-256            [-1, 7, 7, 768]               0\n",
      " StochasticDepth-257            [-1, 7, 7, 768]               0\n",
      "       LayerNorm-258            [-1, 7, 7, 768]           1,536\n",
      "          Linear-259           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-260           [-1, 7, 7, 3072]               0\n",
      "         Dropout-261           [-1, 7, 7, 3072]               0\n",
      "          Linear-262            [-1, 7, 7, 768]       2,360,064\n",
      "         Dropout-263            [-1, 7, 7, 768]               0\n",
      " StochasticDepth-264            [-1, 7, 7, 768]               0\n",
      "SwinTransformerBlock-265            [-1, 7, 7, 768]               0\n",
      "       LayerNorm-266            [-1, 7, 7, 768]           1,536\n",
      "ShiftedWindowAttention-267            [-1, 7, 7, 768]               0\n",
      " StochasticDepth-268            [-1, 7, 7, 768]               0\n",
      "       LayerNorm-269            [-1, 7, 7, 768]           1,536\n",
      "          Linear-270           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-271           [-1, 7, 7, 3072]               0\n",
      "         Dropout-272           [-1, 7, 7, 3072]               0\n",
      "          Linear-273            [-1, 7, 7, 768]       2,360,064\n",
      "         Dropout-274            [-1, 7, 7, 768]               0\n",
      " StochasticDepth-275            [-1, 7, 7, 768]               0\n",
      "SwinTransformerBlock-276            [-1, 7, 7, 768]               0\n",
      "       LayerNorm-277            [-1, 7, 7, 768]           1,536\n",
      "AdaptiveAvgPool2d-278            [-1, 768, 1, 1]               0\n",
      "          Linear-279                 [-1, 1000]         769,000\n",
      " SwinTransformer-280                 [-1, 1000]               0\n",
      "         Dropout-281                 [-1, 1000]               0\n",
      "          Linear-282                   [-1, 50]          50,050\n",
      "================================================================\n",
      "Total params: 33,868,490\n",
      "Trainable params: 33,868,490\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 371.26\n",
      "Params size (MB): 129.20\n",
      "Estimated Total Size (MB): 501.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "model = BaseModel()\n",
    "torchsummary.summary(model, (3,224,224),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_focal_loss(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    alpha: float = 0.25,\n",
    "    gamma: float = 2,\n",
    "    reduction: str = \"mean\",\n",
    "    classes=classes\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "    Args:\n",
    "        inputs (Tensor): A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets (Tensor): A float tensor with the same shape as inputs. Stores the binary\n",
    "                classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha (float): Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples or -1 for ignore. Default: ``0.25``.\n",
    "        gamma (float): Exponent of the modulating factor (1 - p_t) to\n",
    "                balance easy vs hard examples. Default: ``2``.\n",
    "        reduction (string): ``'none'`` | ``'mean'`` | ``'sum'``\n",
    "                ``'none'``: No reduction will be applied to the output.\n",
    "                ``'mean'``: The output will be averaged.\n",
    "                ``'sum'``: The output will be summed. Default: ``'none'``.\n",
    "    Returns:\n",
    "        Loss tensor with the reduction option applied.\n",
    "    \"\"\"\n",
    "    # Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py\n",
    "    p = torch.sigmoid(inputs)\n",
    "    # label smoothing\n",
    "    targets = targets*(1-0.1)+0.1/50\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = p * targets + (1 - p) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "    # # 라벨마다 가중치\n",
    "    # for i in range(targets.shape[0]):\n",
    "    #     k = targets[i].argmax(0).item()\n",
    "    #     more = torch.tensor(classes[list(classes.keys())[k]][1])\n",
    "    #     loss[i] = loss[i]*630/more\n",
    "        \n",
    "    # Check reduction option and return loss accordingly\n",
    "    if reduction == \"none\":\n",
    "        pass\n",
    "    elif reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid Value for arg 'reduction': '{reduction} \\n Supported reduction modes: 'none', 'mean', 'sum'\"\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_metric(true,pred):\n",
    "    \n",
    "    return f1_score(true,pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion,test_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    model_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    val_loss = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(iter(test_loader)):\n",
    "            img, label = img.float().to(device), label.to(device)\n",
    "\n",
    "            model_pred = model(img)\n",
    "\n",
    "            loss = criterion(model_pred, label)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += label.argmax(1).detach().cpu().numpy().tolist()\n",
    "    val_f1 = competition_metric(true_labels, model_preds)\n",
    "    return np.mean(val_loss), val_f1\n",
    "\n",
    "# val_loss, val_score = validation(model,criterion, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, criterion,scheduler, device):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for img , label in tqdm(iter(train_loader)):\n",
    "        img, label = img.float().to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_pred = model(img)\n",
    "\n",
    "        loss = criterion(model_pred, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    tr_loss  = np.mean(np.array(train_loss))\n",
    "\n",
    "    return tr_loss\n",
    "# train_loss = train(model,optimizer, train_loader, criterion,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def kfold_train(base_model, all_images, all_labels,class_info,train_transform,test_transform=None,k=5):\n",
    "    print(f'Total Dataset : {len(all_images)}, {type(all_images)}')\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    total_history = []\n",
    "    data_length = len(all_images)//k\n",
    "    print(data_length)\n",
    "    all_images = np.array(all_images)\n",
    "    all_labels = np.array(all_labels)\n",
    "    c = 0\n",
    "    for train_index, test_index in skf.split(all_images,all_labels):\n",
    "        c+=1\n",
    "        print(f'{c}st Train')\n",
    "        # train_images = all_images.iloc[train_index].values\n",
    "        # train_label = all_labels.iloc[train_index].values\n",
    "\n",
    "        # val_images = all_images.iloc[test_index].values\n",
    "        # val_label = all_labels.iloc[test_index].values\n",
    "        train_images = np.take(all_images,train_index)\n",
    "        train_labels = np.take(all_labels,train_index)\n",
    "\n",
    "        val_images = np.take(all_images,test_index)\n",
    "        val_labels = np.take(all_labels,test_index)\n",
    "\n",
    "        train_dataset = CustomDataset(train_images,train_labels,class_info,train_transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
    "\n",
    "        val_dataset = CustomDataset(val_images,val_labels,class_info,test_transform)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = 16, shuffle=False)\n",
    "\n",
    "        model = base_model()\n",
    "        model.to(device)\n",
    "        epoch = 100\n",
    "        best_f1 = 0\n",
    "        early = 0\n",
    "        history = {'train_loss':[],'val_loss':[],'f1_score':[]}\n",
    "        \n",
    "        optimizer = torch.optim.Adam(params=model.parameters(),lr=5e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=7,gamma=0.5)\n",
    "        # criterion = sigmoid_focal_loss\n",
    "        criterion = F.binary_cross_entropy_with_logits\n",
    "        for e in range(1,epoch):\n",
    "            train_loss = train(model, optimizer, train_loader, criterion,scheduler, device)\n",
    "            val_loss, f1_score = validation(model,criterion,val_loader,device)\n",
    "\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['f1_score'].append(f1_score)\n",
    "\n",
    "            if best_f1 < f1_score:\n",
    "                best_f1 = f1_score\n",
    "                torch.save({\n",
    "                    'epoch': e,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                },f'./checkpoint/best_{c}_conv_small_{f1_score:.3f}.pth')\n",
    "                print('Model Saved')\n",
    "            else:\n",
    "                early +=1\n",
    "                if early > 5:\n",
    "                    print('Early stopping')\n",
    "                    break\n",
    "            print(f'{c} - Epoch [{e}], Train Loss : {train_loss:.5f}, Val Loss : {val_loss:.5f}, Val F1 Score : {f1_score:.3f}')\n",
    "\n",
    "        total_history.append(history)\n",
    "    return total_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset : 10050, <class 'list'>\n",
      "2010\n",
      "1st Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:29<00:00,  2.40it/s]\n",
      "100%|██████████| 126/126 [00:34<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "1 - Epoch [1], Train Loss : 0.35291, Val Loss : 0.29539, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:27<00:00,  2.43it/s]\n",
      "100%|██████████| 126/126 [00:34<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Epoch [2], Train Loss : 0.30752, Val Loss : 0.29539, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:29<00:00,  2.40it/s]\n",
      "100%|██████████| 126/126 [00:34<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Epoch [3], Train Loss : 0.30523, Val Loss : 0.29539, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:27<00:00,  2.43it/s]\n",
      "100%|██████████| 126/126 [00:34<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Epoch [4], Train Loss : 0.30466, Val Loss : 0.29539, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:27<00:00,  2.42it/s]\n",
      "100%|██████████| 126/126 [00:34<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Epoch [5], Train Loss : 0.30950, Val Loss : 0.29539, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:27<00:00,  2.42it/s]\n",
      "100%|██████████| 126/126 [00:36<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Epoch [6], Train Loss : 0.31317, Val Loss : 0.29539, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:26<00:00,  2.44it/s]\n",
      "100%|██████████| 126/126 [00:34<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "2st Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:27<00:00,  2.42it/s]\n",
      "100%|██████████| 126/126 [00:31<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "2 - Epoch [1], Train Loss : 0.16185, Val Loss : 0.11221, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:03<00:00,  2.74it/s]\n",
      "100%|██████████| 126/126 [00:28<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Epoch [2], Train Loss : 0.12368, Val Loss : 0.11221, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:03<00:00,  2.74it/s]\n",
      "100%|██████████| 126/126 [00:28<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Epoch [3], Train Loss : 0.12279, Val Loss : 0.11221, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:03<00:00,  2.74it/s]\n",
      "100%|██████████| 126/126 [00:28<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Epoch [4], Train Loss : 0.12281, Val Loss : 0.11221, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:04<00:00,  2.73it/s]\n",
      "100%|██████████| 126/126 [00:28<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Epoch [5], Train Loss : 0.12246, Val Loss : 0.11221, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:04<00:00,  2.73it/s]\n",
      "100%|██████████| 126/126 [00:28<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Epoch [6], Train Loss : 0.12379, Val Loss : 0.11221, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:03<00:00,  2.74it/s]\n",
      "100%|██████████| 126/126 [00:28<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "3st Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:04<00:00,  2.73it/s]\n",
      "100%|██████████| 126/126 [00:28<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "3 - Epoch [1], Train Loss : 0.23517, Val Loss : 0.10237, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:04<00:00,  2.72it/s]\n",
      "100%|██████████| 126/126 [00:28<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 - Epoch [2], Train Loss : 0.16525, Val Loss : 0.10237, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:04<00:00,  2.73it/s]\n",
      "100%|██████████| 126/126 [00:27<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 - Epoch [3], Train Loss : 0.15750, Val Loss : 0.10237, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:04<00:00,  2.72it/s]\n",
      "100%|██████████| 126/126 [00:27<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 - Epoch [4], Train Loss : 0.15939, Val Loss : 0.10237, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:04<00:00,  2.72it/s]\n",
      "100%|██████████| 126/126 [00:27<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 - Epoch [5], Train Loss : 0.16462, Val Loss : 0.10237, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:04<00:00,  2.73it/s]\n",
      "100%|██████████| 126/126 [00:27<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 - Epoch [6], Train Loss : 0.15828, Val Loss : 0.10237, Val F1 Score : 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [03:05<00:00,  2.72it/s]\n",
      "100%|██████████| 126/126 [00:27<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "4st Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 68/503 [00:25<02:34,  2.81it/s]"
     ]
    }
   ],
   "source": [
    "result = kfold_train(BaseModel,all_imgs, all_labels,classes,train_transform,test_transform,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24c3f2c56578ca93d34255952c36601b421b6ecc37a0d9982e6b92a246c07692"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
